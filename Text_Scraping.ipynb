{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Scraping**\n",
    "\n",
    "This notebook includes the code used to scrape the description pages for both Rhizome and MOMA websites. The resulting data is used for some visualisations as well as storytelling. For Rhizome extracting data was also deemed important to help create medium information for the artworks (based on certain keywords such as html, java, flash etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and path \n",
    "from __future__ import print_function\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "#imports for cleaning and keyword extraction\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "path = '/Users/laurentfintoni/Desktop/University/COURSE DOCS/YEAR 2/EPUB/PROJECT/EPDS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rhizome Scraping**\n",
    "- After some trials with the html construction of the Rhizome artwork pages we decided to grab the div that includes all three possible descriptions (summary, artist statement, description) and clean the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrape summaries, descriptions and artists statements from Rhizome website \n",
    "def url_to_text_rhizome(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    accordion = [p.text.strip() for p in soup.find(id=\"AccordionDescriptionBody\").find_all('div')]\n",
    "    print(url)\n",
    "    return accordion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab URLs from artworks DF, scrape them and return them back to the DF\n",
    "rhz_artworks_extra = pd.read_pickle(path+'Rhizome_data/rhizome_artworks_extra.pkl')\n",
    "urls = rhz_artworks_extra['URL'].to_list()\n",
    "scrapes = [url_to_text_rhizome(u) for u in urls]\n",
    "rhz_artworks_extra_text = rhz_artworks_extra.copy()\n",
    "rhz_artworks_extra_text['Text'] = pd.Series(scrapes)\n",
    "#fix an erroneous ID in original first round of scraping \n",
    "rhz_artworks_extra_text.loc[777, 'ID'] = '926, 1268'\n",
    "rhz_artworks_extra_text = rhz_artworks_extra_text.astype(str)\n",
    "rhz_artworks_extra_text.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOMA Scraping**\n",
    "- For MOMA URLs there was only one possible description on the page but the containing div is repeated elsewhereso we used its parent container to only extract what we needed \n",
    "- We show the process for one dept only, but this was repeated for all of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load department DFs\n",
    "moma_arch_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont.pkl')\n",
    "moma_arch_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod.pkl')\n",
    "moma_design_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_img_cont.pkl')\n",
    "moma_design_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_img_mod.pkl')\n",
    "moma_draw_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont.pkl')\n",
    "moma_draw_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod.pkl')\n",
    "moma_films_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/films_cont.pkl')\n",
    "moma_films_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/films_mod.pkl')\n",
    "moma_fluxus_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_cont.pkl')\n",
    "moma_fluxus_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_mod.pkl')\n",
    "moma_media_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_cont.pkl')\n",
    "moma_media_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_mod.pkl')\n",
    "moma_paint_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont.pkl')\n",
    "moma_paint_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod.pkl')\n",
    "moma_photo_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_cont.pkl')\n",
    "moma_photo_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_mod.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract text if available w/ exclusions for 404 status, missing URLs, and pages w/ no despcription\n",
    "def url_to_text_moma(url):\n",
    "    if url != 'missing':\n",
    "        page = requests.get(url)\n",
    "        status = page.status_code\n",
    "        if status != 404:\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            try:\n",
    "                if soup.find(class_=\"uneven-columns--work\").find(class_='main-content') is not None:\n",
    "                    text = soup.find(class_=\"uneven-columns--work\").find(class_='main-content').find_all('p')\n",
    "                else:\n",
    "                    text = ''\n",
    "            except AttributeError:\n",
    "                text = ''\n",
    "                pass\n",
    "        else:\n",
    "            text = '404'\n",
    "    else:\n",
    "        text = 'missing'     \n",
    "    print(url)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grap all links from a dept as a list \n",
    "links = moma_photo_mod['URL'].to_list()\n",
    "#process links w/ function \n",
    "moma_photo_to_add = [url_to_text_moma(u) for u in links]\n",
    "#add results back to a copy of the original DF\n",
    "moma_photo_mod_text = moma_photo_mod.copy()\n",
    "moma_photo_mod_text['Text'] = moma_photo_to_add\n",
    "moma_photo_mod_text['Text'] = moma_photo_mod_text['Text'].astype(str)\n",
    "moma_photo_mod_text.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rhizome Cleaning & Keywords**\n",
    "- Clean the text of html parsing errors \n",
    "- Analyse most common words for custom stopwords\n",
    "- Run text through nltk english stopwords and custom ones \n",
    "- Extract 20 keywords for each text and add them as a new column (to use for assessing mediums of artworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhz_artworks_extra_text = pd.read_pickle(path+'Rhizome_data/rhizome_artworks_extra_text.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of strings to remove from all scrapes\n",
    "remove = ['description edit\\\\\\\\n\\\\\\\\n\\\\\\\\t\\\\\\\\t\\\\\\\\t\\\\\\\\t', '[', ']', '\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\', '\\'description edit\\', ', 'edit\\\\\\\\n\\\\\\\\n', '\\'summary edit\\', ', 'tttt', 'nn']\n",
    "for char in remove:\n",
    "    rhz_artworks_extra_text['Text'] = rhz_artworks_extra_text['Text'].str.replace(char, '')\n",
    "\n",
    "#export cleaned version to pickle\n",
    "rhz_artworks_extra_text_clean = rhz_artworks_extra_text.copy()\n",
    "rhz_artworks_extra_text_clean.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check top 50 keywords \n",
    "common = pd.Series(' '.join(rhz_artworks_extra_text_clean['Text']).split()).value_counts()[:50]\n",
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of stop words and add custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words =  ['the', 'a ', 'rhizome', '\\'attributed', 'summary', 'to:', '\\'inception:', 'staff\\',', '\\'attribution:', '\\'summary', 'staffinception:', '-', '2021\\',', '\\'legacy', '2001\\',']\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords from cleanedtext \n",
    "rhz_artworks_extra_text_clean['Text'] = rhz_artworks_extra_text_clean['Text'].str.lower()\n",
    "rhz_artworks_extra_text_clean['Text'] = rhz_artworks_extra_text_clean['Text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check top 50 keywords again\n",
    "common_clean = pd.Series(' '.join(rhz_artworks_extra_text_clean['Text']).split()).value_counts()[:50]\n",
    "common_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract keywords and pass them to a new column\n",
    "def get_keywords(row):\n",
    "    some_text = row['Text']\n",
    "    tokens = nltk.tokenize.word_tokenize(some_text)\n",
    "    keywords = [keyword for keyword in tokens if keyword.isalpha() and not keyword in stop_words]\n",
    "    keywords_string = ', '.join(keywords[0:20])\n",
    "    return keywords_string\n",
    "\n",
    "rhz_artworks_extra_text_clean['Keywords'] = rhz_artworks_extra_text_clean.apply(lambda row:get_keywords(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to new pickle for reuse\n",
    "rhz_artworks_extra_text_clean.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text_clean_stop_keywords.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhz_artworks_extra_text_clean.loc[rhz_artworks_extra_text_clean['Keywords'].str.contains('html', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOMA Cleaning**\n",
    "- Clean the text \n",
    "- Remove empty entries and duplicates from DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DFs with text\n",
    "moma_arch_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text.pkl')\n",
    "moma_arch_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only.pkl')\n",
    "moma_draw_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text.pkl')\n",
    "moma_draw_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text.pkl')\n",
    "moma_films_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/films_cont_text.pkl')\n",
    "moma_films_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/films_mod_text.pkl')\n",
    "moma_fluxus_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_cont_text.pkl')\n",
    "moma_fluxus_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_mod_text.pkl')\n",
    "moma_media_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text.pkl')\n",
    "moma_media_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text.pkl')\n",
    "moma_paint_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text.pkl')\n",
    "moma_paint_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text.pkl')\n",
    "moma_photo_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_cont_text.pkl')\n",
    "moma_photo_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DFs to list then clean them \n",
    "moma_texts = [moma_arch_cont_text, moma_draw_cont_text, moma_draw_mod_text, moma_films_cont_text, moma_films_mod_text, moma_fluxus_cont_text, moma_fluxus_mod_text, moma_media_cont_text, moma_media_mod_text, moma_paint_cont_text, moma_paint_mod_text, moma_photo_cont_text, moma_photo_mod_text]\n",
    "\n",
    "remove = ['[', ']', '</p>', '<p>', '<strong>', '</strong>', '<em>', '</em>', '</br>']\n",
    "for text in moma_texts:\n",
    "    for char in remove:\n",
    "        text['Text'] = text['Text'].str.replace(char, '')\n",
    "\n",
    "#exception for DF that was formatted differently due to scraping error (text column only)\n",
    "for char in remove:\n",
    "    moma_arch_mod_text['text'] = moma_arch_mod_text['text'].str.replace(char, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings w/ missing value to filter useful results only\n",
    "moma_arch_cont_text['Text'] = moma_arch_cont_text['Text'].replace([''], 'missing')\n",
    "moma_arch_mod_text['text'] = moma_arch_mod_text['text'].replace([''], 'missing')\n",
    "moma_draw_cont_text['Text'] = moma_draw_cont_text['Text'].replace([''], 'missing')\n",
    "moma_draw_mod_text['Text'] = moma_draw_mod_text['Text'].replace([''], 'missing')\n",
    "moma_films_cont_text['Text'] = moma_films_cont_text['Text'].replace([''], 'missing')\n",
    "moma_films_mod_text['Text'] = moma_films_mod_text['Text'].replace([''], 'missing')\n",
    "moma_fluxus_cont_text['Text'] = moma_fluxus_cont_text['Text'].replace([''], 'missing')\n",
    "moma_fluxus_mod_text['Text'] = moma_fluxus_mod_text['Text'].replace([''], 'missing')\n",
    "moma_media_cont_text['Text'] = moma_media_cont_text['Text'].replace([''], 'missing')\n",
    "moma_media_mod_text['Text'] = moma_media_mod_text['Text'].replace([''], 'missing')\n",
    "moma_paint_cont_text['Text'] = moma_paint_cont_text['Text'].replace([''], 'missing')\n",
    "moma_paint_mod_text['Text'] = moma_paint_mod_text['Text'].replace([''], 'missing')\n",
    "moma_photo_cont_text['Text'] = moma_photo_cont_text['Text'].replace([''], 'missing')\n",
    "moma_photo_mod_text['Text'] = moma_photo_mod_text['Text'].replace([''], 'missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned DFs back \n",
    "moma_arch_cont_text.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text.pkl')\n",
    "moma_arch_mod_text.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only.pkl')\n",
    "moma_draw_cont_text.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text.pkl')\n",
    "moma_draw_mod_text.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text.pkl')\n",
    "moma_films_cont_text.to_pickle(path+'MOMA_data/pickle/departments/films_cont_text.pkl')\n",
    "moma_films_mod_text.to_pickle(path+'MOMA_data/pickle/departments/films_mod_text.pkl')\n",
    "moma_fluxus_cont_text.to_pickle(path+'MOMA_data/pickle/departments/fluxus_cont_text.pkl')\n",
    "moma_fluxus_mod_text.to_pickle(path+'MOMA_data/pickle/departments/fluxus_mod_text.pkl')\n",
    "moma_media_cont_text.to_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text.pkl')\n",
    "moma_media_mod_text.to_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text.pkl')\n",
    "moma_paint_cont_text.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text.pkl')\n",
    "moma_paint_mod_text.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text.pkl')\n",
    "moma_photo_cont_text.to_pickle(path+'MOMA_data/pickle/departments/photo_cont_text.pkl')\n",
    "moma_photo_mod_text.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce DFs down to entries w/ only useful text and remove duplicates \n",
    "moma_arch_cont_text_final = moma_arch_cont_text.loc[moma_arch_cont_text['Text'] != 'missing']\n",
    "moma_arch_cont_text_final = moma_arch_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_arch_mod_text_final = moma_arch_mod_text.loc[moma_arch_mod_text['text'] != 'missing']\n",
    "moma_arch_mod_text_final = moma_arch_mod_text_final.drop_duplicates(subset=['text'])\n",
    "moma_draw_cont_text_final = moma_draw_cont_text.loc[moma_draw_cont_text['Text'] != 'missing']\n",
    "moma_draw_cont_text_final = moma_draw_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_draw_mod_text_final = moma_draw_mod_text.loc[moma_draw_mod_text['Text'] != 'missing']\n",
    "moma_draw_mod_text_final = moma_draw_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_films_cont_text_final = moma_films_cont_text.loc[moma_films_cont_text['Text'] != 'missing']\n",
    "moma_films_cont_text_final = moma_films_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_films_mod_text_final = moma_films_mod_text.loc[moma_films_mod_text['Text'] != 'missing']\n",
    "moma_films_mod_text_final = moma_films_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_fluxus_cont_text_final = moma_fluxus_cont_text.loc[moma_fluxus_cont_text['Text'] != 'missing']\n",
    "moma_fluxus_cont_text_final = moma_fluxus_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_fluxus_mod_text_final = moma_fluxus_mod_text.loc[moma_fluxus_mod_text['Text'] != 'missing']\n",
    "moma_fluxus_mod_text_final = moma_fluxus_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_media_cont_text_final = moma_media_cont_text.loc[moma_media_cont_text['Text'] != 'missing']\n",
    "moma_media_cont_text_final = moma_media_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_media_mod_text_final = moma_media_mod_text.loc[moma_media_mod_text['Text'] != 'missing']\n",
    "moma_media_mod_text_final = moma_media_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_paint_cont_text_final = moma_paint_cont_text.loc[moma_paint_cont_text['Text'] != 'missing']\n",
    "moma_paint_cont_text_final = moma_paint_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_paint_mod_text_final = moma_paint_mod_text.loc[moma_paint_mod_text['Text'] != 'missing']\n",
    "moma_paint_mod_text_final = moma_paint_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_photo_cont_text_final = moma_photo_cont_text.loc[moma_photo_cont_text['Text'] != 'missing']\n",
    "moma_photo_cont_text_final = moma_photo_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_photo_mod_text_final = moma_photo_mod_text.loc[moma_photo_mod_text['Text'] != 'missing']\n",
    "moma_photo_mod_text_final = moma_photo_mod_text_final.drop_duplicates(subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle final results for visualisation \n",
    "moma_arch_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text_final.pkl')\n",
    "moma_arch_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only_final.pkl')\n",
    "moma_draw_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text_final.pkl')\n",
    "moma_draw_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text_final.pkl')\n",
    "moma_films_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_cont_text_final.pkl')\n",
    "moma_films_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_mod_text_final.pkl')\n",
    "moma_fluxus_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/fluxus_cont_text_final.pkl')\n",
    "moma_fluxus_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/fluxus_mod_text_final.pkl')\n",
    "moma_media_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text_final.pkl')\n",
    "moma_media_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text_final.pkl')\n",
    "moma_paint_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text_final.pkl')\n",
    "moma_paint_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text_final.pkl')\n",
    "moma_photo_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_cont_text_final.pkl')\n",
    "moma_photo_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stopwords and remove them\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words =  ['.', 'one', 'two', 'also']\n",
    "stop_words = stop_words.union(new_words)\n",
    "\n",
    "moma_texts_final = [moma_arch_cont_text_final, moma_draw_cont_text_final, moma_draw_mod_text_final, moma_films_cont_text_final, moma_films_mod_text_final, moma_fluxus_cont_text_final, moma_fluxus_mod_text_final, moma_media_cont_text_final, moma_media_mod_text_final, moma_paint_cont_text_final, moma_paint_mod_text_final, moma_photo_cont_text_final, moma_photo_mod_text_final]\n",
    "\n",
    "for text in moma_texts_final:\n",
    "    text['Text'] = text['Text'].str.lower()\n",
    "    text['Text'] = text['Text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "\n",
    "#exception \n",
    "moma_arch_mod_text_final['text'] = moma_arch_mod_text_final['text'].str.lower()\n",
    "moma_arch_mod_text_final['text'] = moma_arch_mod_text_final['text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "design           249\n",
       "new              224\n",
       "architecture     181\n",
       "designed         166\n",
       "modern           155\n",
       "would            143\n",
       "architectural    141\n",
       "city             140\n",
       "work             118\n",
       "urban            108\n",
       "first            100\n",
       "house             98\n",
       "form              92\n",
       "building          92\n",
       "used              91\n",
       "could             91\n",
       "art               88\n",
       "poster            87\n",
       "drawing           84\n",
       "many              74\n",
       "project           73\n",
       "made              72\n",
       "architect         71\n",
       "like              65\n",
       "series            64\n",
       "exhibition        64\n",
       "rather            62\n",
       "forms             61\n",
       "world             59\n",
       "buildings         57\n",
       "war               55\n",
       "international     55\n",
       "drawings          55\n",
       "projects          54\n",
       "create            54\n",
       "elements          54\n",
       "space             54\n",
       "part              54\n",
       "industrial        53\n",
       "well              52\n",
       "early             52\n",
       "created           52\n",
       "became            51\n",
       "inspired          49\n",
       "furniture         49\n",
       "called            48\n",
       "produced          48\n",
       "plan              48\n",
       "developed         48\n",
       "designs           47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_moma = pd.Series(' '.join(moma_arch_mod_text_final['text']).split()).value_counts()[:50]\n",
    "common_moma"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
