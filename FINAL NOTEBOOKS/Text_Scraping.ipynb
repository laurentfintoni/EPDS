{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Scraping**\n",
    "\n",
    "This notebook includes the code used to scrape the description pages for both Rhizome and MOMA websites. The resulting data is used for some visualisations as well as storytelling. For Rhizome extracting data was also deemed important to help create medium information for the artworks (based on certain keywords such as html, java, flash etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and path \n",
    "from __future__ import print_function\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "#imports for cleaning and keyword extraction\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "\n",
    "#function to scrape summaries, descriptions and artists statements from Rhizome website \n",
    "def url_to_text_rhizome(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    accordion = [p.text.strip() for p in soup.find(id=\"AccordionDescriptionBody\").find_all('div')]\n",
    "    print(url)\n",
    "    return accordion\n",
    "\n",
    "#function to extract text from MoMA website w/ exclusions for 404 status, missing URLs, and pages w/ no despcription\n",
    "def url_to_text_moma(url):\n",
    "    if url != 'missing':\n",
    "        page = requests.get(url)\n",
    "        status = page.status_code\n",
    "        if status != 404:\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            try:\n",
    "                if soup.find(class_=\"uneven-columns--work\").find(class_='main-content') is not None:\n",
    "                    text = soup.find(class_=\"uneven-columns--work\").find(class_='main-content').find_all('p')\n",
    "                else:\n",
    "                    text = ''\n",
    "            except AttributeError:\n",
    "                text = ''\n",
    "                pass\n",
    "        else:\n",
    "            text = '404'\n",
    "    else:\n",
    "        text = 'missing'     \n",
    "    print(url)\n",
    "    return text\n",
    "\n",
    "#function to extract keywords and pass them to a new column\n",
    "def get_keywords(row):\n",
    "    punct_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    some_text = row['Text']\n",
    "    tokens = punct_tokenizer.tokenize(some_text)\n",
    "    keywords = [keyword for keyword in tokens if keyword.isalpha() and not keyword in stop_words]\n",
    "    freqdist = nltk.FreqDist(keywords)\n",
    "    most_common = freqdist.most_common(20)\n",
    "    most_common_list = []\n",
    "    for t in most_common:\n",
    "        most_common_list.append(t[0])\n",
    "    keywords_string = ', '.join(most_common_list)\n",
    "    return keywords_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rhizome Scraping**\n",
    "- After some trials with the html construction of the Rhizome artwork pages we decided to grab the div that includes all three possible descriptions (summary, artist statement, description) and clean the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab URLs from artworks DF, scrape them and return them back to the DF\n",
    "rhz_artworks_extra = pd.read_pickle(path+'Rhizome_data/rhizome_artworks_extra.pkl')\n",
    "urls = rhz_artworks_extra['URL'].to_list()\n",
    "scrapes = [url_to_text_rhizome(u) for u in urls]\n",
    "rhz_artworks_extra_text = rhz_artworks_extra.copy()\n",
    "rhz_artworks_extra_text['Text'] = pd.Series(scrapes)\n",
    "#fix an erroneous ID in original first round of scraping \n",
    "rhz_artworks_extra_text.loc[777, 'ID'] = '926, 1268'\n",
    "rhz_artworks_extra_text = rhz_artworks_extra_text.astype(str)\n",
    "rhz_artworks_extra_text.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOMA Scraping**\n",
    "- For MOMA URLs there was only one possible description on the page but the containing div is repeated elsewhereso we used its parent container to only extract what we needed \n",
    "- We show the process for one dept only, but this was repeated for all of them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load department DFs\n",
    "moma_arch_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont.pkl')\n",
    "moma_arch_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod.pkl')\n",
    "moma_design_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_img_cont.pkl')\n",
    "moma_design_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_img_mod.pkl')\n",
    "moma_draw_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont.pkl')\n",
    "moma_draw_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod.pkl')\n",
    "moma_films_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/films_cont.pkl')\n",
    "moma_films_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/films_mod.pkl')\n",
    "moma_fluxus_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_cont.pkl')\n",
    "moma_fluxus_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/fluxus_mod.pkl')\n",
    "moma_media_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_cont.pkl')\n",
    "moma_media_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_mod.pkl')\n",
    "moma_paint_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont.pkl')\n",
    "moma_paint_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod.pkl')\n",
    "moma_photo_cont = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_cont.pkl')\n",
    "moma_photo_mod = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_mod.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grap all links from a dept as a list \n",
    "links = moma_photo_mod['URL'].to_list()\n",
    "#process links w/ function \n",
    "moma_photo_to_add = [url_to_text_moma(u) for u in links]\n",
    "#add results back to a copy of the original DF\n",
    "moma_photo_mod_text = moma_photo_mod.copy()\n",
    "moma_photo_mod_text['Text'] = moma_photo_to_add\n",
    "moma_photo_mod_text['Text'] = moma_photo_mod_text['Text'].astype(str)\n",
    "moma_photo_mod_text.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rhizome Cleaning & Keywords**\n",
    "- Clean the text of html parsing errors \n",
    "- Analyse most common words for custom stopwords\n",
    "- Run text through nltk english stopwords and custom ones \n",
    "- Extract 20 keywords for each text and add them as a new column (to use for assessing mediums of artworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the DF w/ scraped text\n",
    "rhz_artworks_extra_text = pd.read_pickle(path+'Rhizome_data/rhizome_artworks_extra_text.pkl')\n",
    "rhz_artworks_extra_text = rhz_artworks_extra_text.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/gjlb4c2x5qld93w00hwqj3yh0000gn/T/ipykernel_9198/1324036609.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  rhz_artworks_extra_text['Text'] = rhz_artworks_extra_text['Text'].str.replace(char, '')\n"
     ]
    }
   ],
   "source": [
    "#remove all punctuation\n",
    "rhz_artworks_extra_text['Text'] = rhz_artworks_extra_text['Text'].replace(regex=r'[^\\w\\s]', value='')\n",
    "\n",
    "#create a list of strings to remove from all scrapes\n",
    "remove = ['description editnntttt', '[', ']', 'nnn', 'description edit', 'editnn', 'summary edit', 'tttt', 'nn']\n",
    "for char in remove:\n",
    "    rhz_artworks_extra_text['Text'] = rhz_artworks_extra_text['Text'].str.replace(char, '')\n",
    "\n",
    "#export cleaned version to pickle\n",
    "rhz_artworks_extra_text_clean = rhz_artworks_extra_text.copy()\n",
    "rhz_artworks_extra_text_clean.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of stop words and add custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words =  ['rhizome', 'attributed', 'summary', 'inception', 'staff', 'attribution', 'summary', 'legacy', 'nattributed']\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords from cleanedtext \n",
    "rhz_artworks_extra_text_clean['Text'] = rhz_artworks_extra_text_clean['Text'].str.lower()\n",
    "rhz_artworks_extra_text_clean['Text'] = rhz_artworks_extra_text_clean['Text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "#remove errand string\n",
    "rhz_artworks_extra_text_clean['Text'] = rhz_artworks_extra_text_clean['Text'].replace(regex={r'.attributed.': '', r'.legacy descriptive tags.': '', r'.attribution: staff.': '', r'.attribution.': '', r'.inception.': '', r'http[a-z]*\\s': ' '})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract kws and assign them to new column\n",
    "rhz_artworks_extra_text_clean['Keywords'] = rhz_artworks_extra_text_clean.apply(lambda row:get_keywords(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export new pickle for reuse\n",
    "rhz_artworks_extra_text_clean.to_pickle(path+'Rhizome_data/rhizome_artworks_extra_text_clean_stop_keywords.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MOMA Cleaning**\n",
    "- Clean the text \n",
    "- Remove empty entries and duplicates from DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DFs with text\n",
    "moma_arch_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text.pkl')\n",
    "moma_arch_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only.pkl')\n",
    "moma_draw_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text.pkl')\n",
    "moma_draw_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text.pkl')\n",
    "moma_films_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/films_cont_text.pkl')\n",
    "moma_films_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/films_mod_text.pkl')\n",
    "moma_media_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text.pkl')\n",
    "moma_media_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text.pkl')\n",
    "moma_paint_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text.pkl')\n",
    "moma_paint_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text.pkl')\n",
    "moma_photo_cont_text = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_cont_text.pkl')\n",
    "moma_photo_mod_text = pd.read_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d1/gjlb4c2x5qld93w00hwqj3yh0000gn/T/ipykernel_9198/3307028761.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  text['Text'] = text['Text'].str.replace(char, '')\n",
      "/var/folders/d1/gjlb4c2x5qld93w00hwqj3yh0000gn/T/ipykernel_9198/3307028761.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  moma_arch_mod_text['text'] = moma_arch_mod_text['text'].str.replace(char, '')\n"
     ]
    }
   ],
   "source": [
    "#DFs to list then clean them \n",
    "moma_texts = [moma_arch_cont_text, moma_draw_cont_text, moma_draw_mod_text, moma_films_cont_text, moma_films_mod_text, moma_media_cont_text, moma_media_mod_text, moma_paint_cont_text, moma_paint_mod_text, moma_photo_cont_text, moma_photo_mod_text]\n",
    "\n",
    "remove = ['[', ']', '</p>', '<p>', '<strong>', '</strong>', '<em>', '</em>', '</br>']\n",
    "for text in moma_texts:\n",
    "    for char in remove:\n",
    "        text['Text'] = text['Text'].str.replace(char, '')\n",
    "\n",
    "#exception for DF that was formatted differently due to scraping error (it has one column only w/ scraped text)\n",
    "for char in remove:\n",
    "    moma_arch_mod_text['text'] = moma_arch_mod_text['text'].str.replace(char, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace empty strings w/ missing value to filter useful results only\n",
    "moma_arch_cont_text['Text'] = moma_arch_cont_text['Text'].replace([''], 'missing')\n",
    "moma_arch_mod_text['text'] = moma_arch_mod_text['text'].replace([''], 'missing')\n",
    "moma_draw_cont_text['Text'] = moma_draw_cont_text['Text'].replace([''], 'missing')\n",
    "moma_draw_mod_text['Text'] = moma_draw_mod_text['Text'].replace([''], 'missing')\n",
    "moma_films_cont_text['Text'] = moma_films_cont_text['Text'].replace([''], 'missing')\n",
    "moma_films_mod_text['Text'] = moma_films_mod_text['Text'].replace([''], 'missing')\n",
    "moma_media_cont_text['Text'] = moma_media_cont_text['Text'].replace([''], 'missing')\n",
    "moma_media_mod_text['Text'] = moma_media_mod_text['Text'].replace([''], 'missing')\n",
    "moma_paint_cont_text['Text'] = moma_paint_cont_text['Text'].replace([''], 'missing')\n",
    "moma_paint_mod_text['Text'] = moma_paint_mod_text['Text'].replace([''], 'missing')\n",
    "moma_photo_cont_text['Text'] = moma_photo_cont_text['Text'].replace([''], 'missing')\n",
    "moma_photo_mod_text['Text'] = moma_photo_mod_text['Text'].replace([''], 'missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned DFs back \n",
    "moma_arch_cont_text.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text.pkl')\n",
    "moma_arch_mod_text.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only.pkl')\n",
    "moma_draw_cont_text.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text.pkl')\n",
    "moma_draw_mod_text.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text.pkl')\n",
    "moma_films_cont_text.to_pickle(path+'MOMA_data/pickle/departments/films_cont_text.pkl')\n",
    "moma_films_mod_text.to_pickle(path+'MOMA_data/pickle/departments/films_mod_text.pkl')\n",
    "moma_media_cont_text.to_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text.pkl')\n",
    "moma_media_mod_text.to_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text.pkl')\n",
    "moma_paint_cont_text.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text.pkl')\n",
    "moma_paint_mod_text.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text.pkl')\n",
    "moma_photo_cont_text.to_pickle(path+'MOMA_data/pickle/departments/photo_cont_text.pkl')\n",
    "moma_photo_mod_text.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce DFs down to entries w/ only useful text and remove duplicates \n",
    "moma_arch_cont_text_final = moma_arch_cont_text.loc[moma_arch_cont_text['Text'] != 'missing']\n",
    "moma_arch_cont_text_final = moma_arch_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_arch_mod_text_final = moma_arch_mod_text.loc[moma_arch_mod_text['text'] != 'missing']\n",
    "moma_arch_mod_text_final = moma_arch_mod_text_final.drop_duplicates(subset=['text'])\n",
    "moma_draw_cont_text_final = moma_draw_cont_text.loc[moma_draw_cont_text['Text'] != 'missing']\n",
    "moma_draw_cont_text_final = moma_draw_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_draw_mod_text_final = moma_draw_mod_text.loc[moma_draw_mod_text['Text'] != 'missing']\n",
    "moma_draw_mod_text_final = moma_draw_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_films_cont_text_final = moma_films_cont_text.loc[moma_films_cont_text['Text'] != 'missing']\n",
    "moma_films_cont_text_final = moma_films_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_films_mod_text_final = moma_films_mod_text.loc[moma_films_mod_text['Text'] != 'missing']\n",
    "moma_films_mod_text_final = moma_films_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_media_cont_text_final = moma_media_cont_text.loc[moma_media_cont_text['Text'] != 'missing']\n",
    "moma_media_cont_text_final = moma_media_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_media_mod_text_final = moma_media_mod_text.loc[moma_media_mod_text['Text'] != 'missing']\n",
    "moma_media_mod_text_final = moma_media_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_paint_cont_text_final = moma_paint_cont_text.loc[moma_paint_cont_text['Text'] != 'missing']\n",
    "moma_paint_cont_text_final = moma_paint_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_paint_mod_text_final = moma_paint_mod_text.loc[moma_paint_mod_text['Text'] != 'missing']\n",
    "moma_paint_mod_text_final = moma_paint_mod_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_photo_cont_text_final = moma_photo_cont_text.loc[moma_photo_cont_text['Text'] != 'missing']\n",
    "moma_photo_cont_text_final = moma_photo_cont_text_final.drop_duplicates(subset=['Text'])\n",
    "moma_photo_mod_text_final = moma_photo_mod_text.loc[moma_photo_mod_text['Text'] != 'missing']\n",
    "moma_photo_mod_text_final = moma_photo_mod_text_final.drop_duplicates(subset=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle final results for visualisation \n",
    "moma_arch_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text_final.pkl')\n",
    "moma_arch_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only_final.pkl')\n",
    "moma_draw_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text_final.pkl')\n",
    "moma_draw_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text_final.pkl')\n",
    "moma_films_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_cont_text_final.pkl')\n",
    "moma_films_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_mod_text_final.pkl')\n",
    "moma_media_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text_final.pkl')\n",
    "moma_media_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text_final.pkl')\n",
    "moma_paint_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text_final.pkl')\n",
    "moma_paint_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text_final.pkl')\n",
    "moma_photo_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_cont_text_final.pkl')\n",
    "moma_photo_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stopwords and remove them\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "new_words =  ['.', 'one', 'two', 'also']\n",
    "stop_words = stop_words.union(new_words)\n",
    "\n",
    "moma_texts_final = [moma_arch_cont_text_final, moma_draw_cont_text_final, moma_draw_mod_text_final, moma_films_cont_text_final, moma_films_mod_text_final, moma_media_cont_text_final, moma_media_mod_text_final, moma_paint_cont_text_final, moma_paint_mod_text_final, moma_photo_cont_text_final, moma_photo_mod_text_final]\n",
    "\n",
    "for text in moma_texts_final:\n",
    "    text['Text'] = text['Text'].str.lower()\n",
    "    text['Text'] = text['Text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
    "\n",
    "#exception \n",
    "moma_arch_mod_text_final['text'] = moma_arch_mod_text_final['text'].str.lower()\n",
    "moma_arch_mod_text_final['text'] = moma_arch_mod_text_final['text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get keywords \n",
    "def get_keywords_2(row):\n",
    "    punct_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    some_text = row['text']\n",
    "    tokens = punct_tokenizer.tokenize(some_text)\n",
    "    keywords = [keyword for keyword in tokens if keyword.isalpha() and not keyword in stop_words]\n",
    "    freqdist = nltk.FreqDist(keywords)\n",
    "    most_common = freqdist.most_common(20)\n",
    "    most_common_list = []\n",
    "    for t in most_common:\n",
    "        most_common_list.append(t[0])\n",
    "    keywords_string = ', '.join(most_common_list)\n",
    "    return keywords_string\n",
    "\n",
    "moma_arch_cont_text_final['Keywords'] = moma_arch_cont_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_draw_cont_text_final['Keywords'] = moma_draw_cont_text_final.apply(lambda row:get_keywords(row), axis=1) \n",
    "moma_draw_mod_text_final['Keywords'] = moma_draw_mod_text_final.apply(lambda row:get_keywords(row), axis=1) \n",
    "moma_films_cont_text_final['Keywords'] = moma_films_cont_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_films_mod_text_final['Keywords'] = moma_films_mod_text_final.apply(lambda row:get_keywords(row), axis=1) \n",
    "moma_media_cont_text_final['Keywords'] = moma_media_cont_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_media_mod_text_final['Keywords'] = moma_media_mod_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_paint_cont_text_final['Keywords'] = moma_paint_cont_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_paint_mod_text_final['Keywords'] = moma_paint_mod_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_photo_cont_text_final['Keywords'] = moma_photo_cont_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_photo_mod_text_final['Keywords'] = moma_photo_mod_text_final.apply(lambda row:get_keywords(row), axis=1)\n",
    "moma_arch_mod_text_final['Keywords'] = moma_arch_mod_text_final.apply(lambda row:get_keywords_2(row), axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle version w/ stopwords removed and keywords added\n",
    "moma_arch_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_cont_text_final_stop.pkl')\n",
    "moma_arch_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/architecture_design_mod_text_only_final_stop.pkl')\n",
    "moma_draw_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_cont_text_final_stop.pkl')\n",
    "moma_draw_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/draws_prints_mod_text_final_stop.pkl')\n",
    "moma_films_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_cont_text_final_stop.pkl')\n",
    "moma_films_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/films_mod_text_final_stop.pkl')\n",
    "moma_media_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_cont_text_final_stop.pkl')\n",
    "moma_media_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/media_perf_mod_text_final_stop.pkl')\n",
    "moma_paint_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_cont_text_final_stop.pkl')\n",
    "moma_paint_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/paint_sculp_mod_text_final_stop.pkl')\n",
    "moma_photo_cont_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_cont_text_final_stop.pkl')\n",
    "moma_photo_mod_text_final.to_pickle(path+'MOMA_data/pickle/departments/photo_mod_text_final_stop.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
